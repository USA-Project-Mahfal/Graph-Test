{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "870b0ec3",
   "metadata": {},
   "source": [
    "# Advanced Graph Build\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79423081",
   "metadata": {},
   "source": [
    "## Filter Master CSV to First 6 Categories\n",
    "\n",
    "Process:\n",
    "1. Load the full `master_clauses.csv`.  \n",
    "2. Select our six clause-of-interest columns (`Parties`, `Agreement Date`, `Effective Date`, `Expiration Date`, `Renewal Term`, `Notice Period To Terminate Renewal`) plus their corresponding “-Answer” fields.  \n",
    "3. Filter the DataFrame to retain only contracts with at least one non-empty/positive answer.  \n",
    "4. Reset the index and save the result to `filtered_master_clauses.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df48c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 509 contracts out of 510 total.\n",
      "                                            Filename  \\\n",
      "0  CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...   \n",
      "1  EuromediaHoldingsCorp_20070215_10SB12G_EX-10.B...   \n",
      "2  FulucaiProductionsLtd_20131223_10-Q_EX-10.9_83...   \n",
      "3  GopageCorp_20140221_10-K_EX-10.1_8432966_EX-10...   \n",
      "4  IdeanomicsInc_20160330_10-K_EX-10.26_9512211_E...   \n",
      "\n",
      "                                             Parties  \\\n",
      "0  ['BIRCH FIRST GLOBAL INVESTMENTS INC.', 'MA', ...   \n",
      "1  ['EuroMedia Holdings Corp.', 'Rogers', 'Rogers...   \n",
      "2  ['Producer', 'Fulucai Productions Ltd.', 'Conv...   \n",
      "3  ['PSiTech Corporation', 'Licensor', 'Licensee'...   \n",
      "4  ['YOU ON DEMAND HOLDINGS, INC.', 'Licensor', '...   \n",
      "\n",
      "                           Agreement Date  \\\n",
      "0  ['8th day of May 2014', 'May 8, 2014']   \n",
      "1                      ['July 11 , 2006']   \n",
      "2                   ['November 15, 2012']   \n",
      "3                        ['Feb 10, 2014']   \n",
      "4                   ['December 21, 2015']   \n",
      "\n",
      "                                      Effective Date  \\\n",
      "0  ['This agreement shall begin upon the date of ...   \n",
      "1                                 ['July 11 , 2006']   \n",
      "2                              ['November 15, 2012']   \n",
      "3                                   ['Feb 10, 2014']   \n",
      "4                              ['December 21, 2015']   \n",
      "\n",
      "                                     Expiration Date  \\\n",
      "0  ['This agreement shall begin upon the date of ...   \n",
      "1  ['The term of this Agreement (the \"Initial Ter...   \n",
      "2                                                 []   \n",
      "3  ['The initial term of this Agreement commences...   \n",
      "4  ['The Term of this Agreement (the \"Term\") shal...   \n",
      "\n",
      "                                        Renewal Term  \\\n",
      "0  ['This agreement shall begin upon the date of ...   \n",
      "1  ['At Rogers\\' option, this Agreement shall ren...   \n",
      "2  ['License Term Perpetual, unlimited runs x Oth...   \n",
      "3  ['Thereafter, this Agreement shall renew autom...   \n",
      "4                                                 []   \n",
      "\n",
      "                  Notice Period To Terminate Renewal  \\\n",
      "0  ['This Agreement may be terminated by either p...   \n",
      "1  [\"Notwithstanding the foregoing, if, at the ex...   \n",
      "2                                                 []   \n",
      "3  ['Thereafter, this Agreement shall renew autom...   \n",
      "4                                                 []   \n",
      "\n",
      "                                      Parties-Answer Agreement Date-Answer  \\\n",
      "0  Birch First Global Investments Inc. (\"Company\"...                5/8/14   \n",
      "1  Rogers Cable Communications Inc. (\"Rogers\"); E...               7/11/06   \n",
      "2  CONVERGTV, INC. (“ConvergTV”); Fulucai Product...              11/15/12   \n",
      "3  PSiTech Corporation (\"Licensor\"); Empirical Ve...               2/10/14   \n",
      "4  Beijing Sun Seven Stars Culture Development Li...              12/21/15   \n",
      "\n",
      "  Effective Date-Answer Expiration Date-Answer    Renewal Term-Answer  \\\n",
      "0                   NaN               12/31/14      successive 1 year   \n",
      "1               7/11/06                6/30/10                2 years   \n",
      "2              11/15/12                    NaN  perpetual, 11/15/2014   \n",
      "3               2/10/14                2/10/19                3 years   \n",
      "4              12/21/15               12/21/35                    NaN   \n",
      "\n",
      "  Notice Period To Terminate Renewal- Answer  \n",
      "0                                    30 days  \n",
      "1                                    60 days  \n",
      "2                                        NaN  \n",
      "3                                    90 days  \n",
      "4                                        NaN  \n",
      "Saved filtered CSV to /mnt/data/mini_cuad_master_first6.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the master CSV\n",
    "df_master = pd.read_csv(r'C:\\Repositories\\USA_Project\\Graph-Test\\master_clauses.csv')\n",
    "\n",
    "# 2. Exact column names for our first six categories:\n",
    "context_cols = [\n",
    "    \"Parties\",\n",
    "    \"Agreement Date\",\n",
    "    \"Effective Date\",\n",
    "    \"Expiration Date\",\n",
    "    \"Renewal Term\",\n",
    "    \"Notice Period To Terminate Renewal\"\n",
    "]\n",
    "\n",
    "# Note the precise answer column names (matching the CSV):\n",
    "answer_cols = [\n",
    "    \"Parties-Answer\",\n",
    "    \"Agreement Date-Answer\",\n",
    "    \"Effective Date-Answer\",\n",
    "    \"Expiration Date-Answer\",\n",
    "    \"Renewal Term-Answer\",\n",
    "    \"Notice Period To Terminate Renewal- Answer\"\n",
    "]\n",
    "\n",
    "# 3. Subset to these columns + Filename\n",
    "cols_to_keep = [\"Filename\"] + context_cols + answer_cols\n",
    "df_sub = df_master[cols_to_keep].copy()\n",
    "\n",
    "# 4. Filter to rows where at least one answer is non-empty/positive\n",
    "mask = pd.Series(False, index=df_sub.index)\n",
    "for ans in answer_cols:\n",
    "    mask |= df_sub[ans].notna() & ~df_sub[ans].isin([\"No\", \"[]\", \"\"])\n",
    "df_mini = df_sub[mask].reset_index(drop=True)\n",
    "\n",
    "# 5. Inspect and save\n",
    "print(f\"Filtered to {len(df_mini)} contracts out of {len(df_master)} total.\")\n",
    "print(df_mini.head())\n",
    "\n",
    "df_mini.to_csv(r'C:\\Repositories\\USA_Project\\Graph-Test\\filtered_master_clauses.csv', index=False)\n",
    "print(\"Saved filtered CSV to /mnt/data/mini_cuad_master_first6.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a29589f",
   "metadata": {},
   "source": [
    "## Explode to Clause-Level Snippets\n",
    "\n",
    "Process:\n",
    "1. Read `filtered_master_clauses.csv` (contract-level).  \n",
    "2. Define the six clause context columns.  \n",
    "3. Iterate over each contract and each context column, extracting non-empty snippets.  \n",
    "4. Build a snippet-level DataFrame with columns:  \n",
    "   - `doc_idx` (contract row index)  \n",
    "   - `filename`  \n",
    "   - `category`  \n",
    "   - `snippet_text`  \n",
    "5. Save the snippet DataFrame to `mini_cuad_snippets.csv`.\n",
    "\n",
    "Basically for each doc which has a true value for snippet we retrieve the snippet data into a single row.\n",
    "So if a document has values for multiple clauses , it'll have multiple columns here. These will be the children nodes. While document is the parent node.\n",
    "Check mini_cuad_snippets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b44118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2069 snippets:\n",
      "   doc_idx                                           filename  \\\n",
      "0        0  CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...   \n",
      "1        0  CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...   \n",
      "2        0  CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...   \n",
      "3        0  CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...   \n",
      "4        0  CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...   \n",
      "\n",
      "          category                                       snippet_text  \n",
      "0          Parties  ['BIRCH FIRST GLOBAL INVESTMENTS INC.', 'MA', ...  \n",
      "1   Agreement Date             ['8th day of May 2014', 'May 8, 2014']  \n",
      "2   Effective Date  ['This agreement shall begin upon the date of ...  \n",
      "3  Expiration Date  ['This agreement shall begin upon the date of ...  \n",
      "4     Renewal Term  ['This agreement shall begin upon the date of ...  \n",
      "Snippet‐level CSV saved to /mnt/data/mini_cuad_snippets.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the filtered master CSV\n",
    "df_filtered = pd.read_csv(r'C:\\Repositories\\USA_Project\\Graph-Test\\filtered_master_clauses.csv')\n",
    "\n",
    "# 2. Define the six clause context columns exactly\n",
    "context_cols = [\n",
    "    \"Parties\",\n",
    "    \"Agreement Date\",\n",
    "    \"Effective Date\",\n",
    "    \"Expiration Date\",\n",
    "    \"Renewal Term\",\n",
    "    \"Notice Period To Terminate Renewal\"\n",
    "]\n",
    "\n",
    "# 3. Explode into one row per non-empty snippet\n",
    "rows = []\n",
    "for doc_idx, row in df_filtered.reset_index(drop=True).iterrows():\n",
    "    for cat in context_cols:\n",
    "        snippet = row[cat]\n",
    "        if pd.notna(snippet) and snippet not in [\"\", \"No\", \"[]\"]:\n",
    "            rows.append({\n",
    "                \"doc_idx\": doc_idx,\n",
    "                \"filename\": row[\"Filename\"],\n",
    "                \"category\": cat,\n",
    "                \"snippet_text\": snippet.strip()\n",
    "            })\n",
    "\n",
    "snips_df = pd.DataFrame(rows)\n",
    "\n",
    "# 4. Inspect and save\n",
    "print(f\"Extracted {len(snips_df)} snippets:\")\n",
    "print(snips_df.head())\n",
    "\n",
    "snips_df.to_csv(r'C:\\Repositories\\USA_Project\\Graph-Test\\mini_cuad_snippets.csv', index=False)\n",
    "print(\"Snippet‐level CSV saved to /mnt/data/mini_cuad_snippets.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11db53d",
   "metadata": {},
   "source": [
    "## Embed Clause Snippets\n",
    "\n",
    "\n",
    "1. Load the snippet‐level CSV (`mini_cuad_snippets.csv`) produced in the previous step.  \n",
    "2. Initialize a legal‐domain SBERT model (`Stern5497/sbert-legal-xlm-roberta-base`).  [Stil testing with this model]\n",
    "3. Encode each `snippet_text` into a dense vector, storing the result in a new `embedding` column.  \n",
    "4. Persist the enriched DataFrame to `mini_cuad_snippets_emb.pkl` for downstream graph construction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a998ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load snippet table\n",
    "snips = pd.read_csv(r'C:\\Repositories\\USA_Project\\Graph-Test\\mini_cuad_snippets.csv')\n",
    "\n",
    "# 2. Initialize a legal SBERT model\n",
    "model = SentenceTransformer('Stern5497/sbert-legal-xlm-roberta-base')\n",
    "\n",
    "# 3. Embed snippets\n",
    "snip_texts = snips['snippet_text'].tolist()\n",
    "snip_embs  = model.encode(snip_texts, show_progress_bar=True)\n",
    "snips['embedding'] = list(snip_embs)\n",
    "snips.to_pickle(r'C:\\Repositories\\USA_Project\\Graph-Test\\mini_cuad_snippets_emb.pkl')\n",
    "print(f\"Encoded {len(snip_embs)} snippets.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712f903",
   "metadata": {},
   "source": [
    "## Test – Verify TXT File Presence\n",
    "\n",
    "First tried this, \n",
    "1. Load `filtered_master_clauses.csv`.  \n",
    "2. List all expected PDF filenames.  \n",
    "3. Check for each whether a corresponding `.txt` exists in `full_contract_txt`, and record its file size.  \n",
    "4. Display a summary table of existence counts and identify any missing or empty files.\n",
    "\n",
    "Because of slight mismatch of names like `_` instead of `'`\n",
    "\n",
    "### Test – Fuzzy Match Basenames\n",
    "1. List all actual `.txt` basenames in the `full_contract_txt` folder.  \n",
    "2. For each PDF basename with no direct match, use `difflib.get_close_matches` (cutoff=0.8) to propose the closest `.txt` basename.  \n",
    "3. Display the mapping suggestions to review and ensure slight naming differences (underscores, punctuation) are handled automatically.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41569f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer('Stern5497/sbert-legal-xlm-roberta-base')\n",
    "\n",
    "# # 4. Embed full contracts\n",
    "# master   = pd.read_csv(r'C:\\Repositories\\USA_Project\\Graph-Test\\filtered_master_clauses.csv')\n",
    "# files    = master['Filename'].unique()\n",
    "# BASE_TXT_DIR = r'C:\\Repositories\\USA_Project\\Graph-Test\\CUAD_v1\\full_contract_txt'\n",
    "\n",
    "\n",
    "# doc_texts = []\n",
    "# for fname in files:\n",
    "#     # Split off the extension (whether .pdf, .PDF, .Pdf, etc.)\n",
    "#     base, _ = os.path.splitext(fname)\n",
    "#     txt_name = base + '.txt'\n",
    "#     txt_path = os.path.join(BASE_TXT_DIR, txt_name)\n",
    "\n",
    "#     try:\n",
    "#         with open(txt_path, encoding='utf-8', errors='ignore') as f:\n",
    "#             doc_texts.append(f.read())\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"⚠️  Missing {txt_path}, adding empty text\")\n",
    "#         doc_texts.append(\"\")\n",
    "\n",
    "\n",
    "# doc_embs = model.encode(doc_texts, show_progress_bar=True)\n",
    "# docs_df  = pd.DataFrame({'Filename': files, 'embedding': list(doc_embs)})\n",
    "# docs_df.to_pickle(r'C:\\Repositories\\USA_Project\\Graph-Test\\mini_cuad_docs_emb.pkl')\n",
    "# print(f\"Encoded {len(doc_embs)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271f23be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Filename  \\\n",
      "0   CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...   \n",
      "1   EuromediaHoldingsCorp_20070215_10SB12G_EX-10.B...   \n",
      "2   FulucaiProductionsLtd_20131223_10-Q_EX-10.9_83...   \n",
      "3   GopageCorp_20140221_10-K_EX-10.1_8432966_EX-10...   \n",
      "4   IdeanomicsInc_20160330_10-K_EX-10.26_9512211_E...   \n",
      "5   DeltathreeInc_19991102_S-1A_EX-10.19_6227850_E...   \n",
      "6   EdietsComInc_20001030_10QSB_EX-10.4_2606646_EX...   \n",
      "7   IntegrityMediaInc_20010329_10-K405_EX-10.17_23...   \n",
      "8   MusclepharmCorp_20170208_10-KA_EX-10.38_989358...   \n",
      "9   TomOnlineInc_20060501_20-F_EX-4.46_749700_EX-4...   \n",
      "10  ConformisInc_20191101_10-Q_EX-10.6_11861402_EX...   \n",
      "11  EtonPharmaceuticalsInc_20191114_10-Q_EX-10.1_1...   \n",
      "12  FuelcellEnergyInc_20191106_8-K_EX-10.1_1186800...   \n",
      "13  ReedsInc_20191113_10-Q_EX-10.4_11888303_EX-10....   \n",
      "14  FuseMedicalInc_20190321_10-K_EX-10.43_11575454...   \n",
      "15  GentechHoldingsInc_20190808_1-A_EX1A-6 MAT CTR...   \n",
      "16  ImineCorp_20180725_S-1_EX-10.5_11275970_EX-10....   \n",
      "17  InnerscopeHearingTechnologiesInc_20181109_8-K_...   \n",
      "18  WaterNowInc_20191120_10-Q_EX-10.12_11900227_EX...   \n",
      "19  GridironBionutrientsInc_20171206_8-K_EX-10.2_1...   \n",
      "\n",
      "                                              TxtName  Exists  SizeBytes  \n",
      "0   CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...    True      33829  \n",
      "1   EuromediaHoldingsCorp_20070215_10SB12G_EX-10.B...    True      30050  \n",
      "2   FulucaiProductionsLtd_20131223_10-Q_EX-10.9_83...    True      18565  \n",
      "3   GopageCorp_20140221_10-K_EX-10.1_8432966_EX-10...    True      39625  \n",
      "4   IdeanomicsInc_20160330_10-K_EX-10.26_9512211_E...    True      41030  \n",
      "5   DeltathreeInc_19991102_S-1A_EX-10.19_6227850_E...    True      28825  \n",
      "6   EdietsComInc_20001030_10QSB_EX-10.4_2606646_EX...    True      64192  \n",
      "7   IntegrityMediaInc_20010329_10-K405_EX-10.17_23...    True      29253  \n",
      "8   MusclepharmCorp_20170208_10-KA_EX-10.38_989358...    True      87805  \n",
      "9   TomOnlineInc_20060501_20-F_EX-4.46_749700_EX-4...    True     112387  \n",
      "10  ConformisInc_20191101_10-Q_EX-10.6_11861402_EX...    True      63218  \n",
      "11  EtonPharmaceuticalsInc_20191114_10-Q_EX-10.1_1...    True      65652  \n",
      "12  FuelcellEnergyInc_20191106_8-K_EX-10.1_1186800...    True     105676  \n",
      "13  ReedsInc_20191113_10-Q_EX-10.4_11888303_EX-10....    True      28343  \n",
      "14  FuseMedicalInc_20190321_10-K_EX-10.43_11575454...    True      32502  \n",
      "15  GentechHoldingsInc_20190808_1-A_EX1A-6 MAT CTR...    True      26753  \n",
      "16  ImineCorp_20180725_S-1_EX-10.5_11275970_EX-10....    True      34461  \n",
      "17  InnerscopeHearingTechnologiesInc_20181109_8-K_...    True      22396  \n",
      "18  WaterNowInc_20191120_10-Q_EX-10.12_11900227_EX...    True      48412  \n",
      "19  GridironBionutrientsInc_20171206_8-K_EX-10.2_1...    True       3474  \n",
      "\n",
      "Existence counts:\n",
      " Exists\n",
      "True     498\n",
      "False     11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing files:\n",
      " ['PLAYAHOTELS&RESORTSNV_03_14_2017-EX-10.22-STRATEGIC ALLIANCE AGREEMENT (Hyatt Ziva Cancun).txt', \"MACY'S,INC_05_11_2020-EX-99.4-JOINT FILING AGREEMENT.txt\", 'MOELIS&CO_03_24_2014-EX-10.19-STRATEGIC ALLIANCE AGREEMENT.txt', 'ELECTRAMECCANICA VEHICLES CORP. - Manufacturing Agreement .txt', 'Monsanto Company - SECOND A&R EXCLUSIVE AGENCY AND MARKETING AGREEMENT .txt', 'LECLANCHÉ S.A. - JOINT DEVELOPMENT AND MARKETING AGREEMENT.txt', 'PACIRA PHARMACEUTICALS, INC. - A&R STRATEGIC LICENSING, DISTRIBUTION AND MARKETING AGREEMENT .txt', 'Principal Life Insurance Company - Broker Dealer Marketing and Servicing Agreement .txt', 'Reinsurance Group of America, Incorporated - A&R REMARKETING  AGREEMENT.txt', 'SightLife Surgical, Inc. - STRATEGIC SALES & MARKETING AGREEMENT.txt', 'NETGEAR,INC_04_21_2003-EX-10.16-AMENDMENT TO THE DISTRIBUTOR AGREEMENT BETWEEN INGRAM MICRO AND NETGEAR-.txt']\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # Adjust to your local paths\n",
    "# filtered_csv = r'C:\\Repositories\\USA_Project\\Graph-Test\\filtered_master_clauses.csv'\n",
    "# BASE_TXT_DIR = r'C:\\Repositories\\USA_Project\\Graph-Test\\CUAD_v1\\full_contract_txt'\n",
    "\n",
    "# master = pd.read_csv(filtered_csv)\n",
    "# files = master['Filename'].unique().tolist()\n",
    "\n",
    "# checks = []\n",
    "# for fname in files:\n",
    "#     base, _ = os.path.splitext(fname)\n",
    "#     txt_name = base + '.txt'\n",
    "#     txt_path = os.path.join(BASE_TXT_DIR, txt_name)\n",
    "#     exists = os.path.exists(txt_path)\n",
    "#     size = os.path.getsize(txt_path) if exists else 0\n",
    "#     checks.append({'Filename': fname, 'TxtName': txt_name, 'Exists': exists, 'SizeBytes': size})\n",
    "\n",
    "# df_checks = pd.DataFrame(checks)\n",
    "# print(df_checks.head(20))\n",
    "# print(\"\\nExistence counts:\\n\", df_checks['Exists'].value_counts())\n",
    "# print(\"\\nMissing files:\\n\", df_checks.loc[~df_checks['Exists'], 'TxtName'].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a556c67",
   "metadata": {},
   "source": [
    "## Final Load & Embed Contracts with Automatic Mapping\n",
    "\n",
    "1. Build an in-memory mapping from each PDF basename to the best matching TXT basename (exact or fuzzy).  \n",
    "2. Load each contract’s text via that mapping (falling back to `\"\"` if still unmatched).  \n",
    "3. Encode all contract texts with the legal SBERT model `Stern5497/sbert-legal-xlm-roberta-base`.  \n",
    "4. Save the resulting DataFrame of (`Filename`, `embedding`) to `mini_cuad_docs_emb.pkl`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f8b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0\n",
      "0   Exhibit 10.27\\n\\nMARKETING AFFILIATE AGREEMENT...\n",
      "1   Exhibit 10.B.01 EXECUTION COPY\\n\\nVIDEO-ON-DEM...\n",
      "2   CONTENT DISTRIBUTION AND LICENSE AGREEMENT   D...\n",
      "3   CONFIDENTIAL\\n\\n  PSiTECHCORPORATION   WEBSITE...\n",
      "4   CONTENT LICENSE AGREEMENT\\n\\nTHIS CONTENT LICE...\n",
      "5   Execution Copy\\n\\n                       CO-BR...\n",
      "6   EXHIBIT 10.4\\n\\n                              ...\n",
      "7   1                                             ...\n",
      "8   ENDORSEMENT LICENSING AND CO-BRANDING AGREEMEN...\n",
      "9   Exhibit 4.46     6 rue Adolphe Fischer L-1520 ...\n",
      "10  Execution Version Certain identified informati...\n",
      "11  Exhibit 10.1 Certain information identified by...\n",
      "12  EXHIBIT 10.1\\n\\nJOINT DEVELOPMENT AGREEMENT\\n\\...\n",
      "13  RECIPE DEVELOPMENT AGREEMENT This Recipe Devel...\n",
      "14  EXHIBIT 10.43 Dated 29/3/18\\n\\nDistributorship...\n",
      "15  Exhibit 6.1 DISTRIBUTOR AGREEMENT THIS DISTRIB...\n",
      "16  EXHIBIT 10.5 NON-EXCLUSIVE DISTRIBUTOR AGREEME...\n",
      "17  Exhibit 10.6 ATTACHMENT A ERCHONIA CORPORATION...\n",
      "18  Exhibit 10.12 EXCLUSIVE DISTRIBUTOR AGREEMENT ...\n",
      "19  EXHIBIT 10.2   ENDORSEMENT AGREEMENT ADDENDUM ...\n",
      "There are 509 rows and 1 columns.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import difflib\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ── CONFIGURE THESE THREE PATHS ────────────────────────────────\n",
    "CSV_PATH    = r'C:\\Repositories\\USA_Project\\Graph-Test\\filtered_master_clauses.csv'\n",
    "TXT_FOLDER  = r'C:\\Repositories\\USA_Project\\Graph-Test\\CUAD_v1\\full_contract_txt'\n",
    "OUTPUT_PKL  = r'C:\\Repositories\\USA_Project\\Graph-Test\\mini_cuad_docs_emb.pkl'\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "# 1. Load the list of filenames from your filtered master CSV\n",
    "df_master = pd.read_csv(CSV_PATH)\n",
    "pdf_files = df_master['Filename'].unique().tolist()\n",
    "\n",
    "# 2. List the actual .txt files on disk and strip off their extensions\n",
    "all_txt = os.listdir(TXT_FOLDER)\n",
    "txt_basenames = {os.path.splitext(f)[0]: f for f in all_txt}\n",
    "\n",
    "# 3. Build a mapping PDF-basename → TXT-basename (fuzzy match if needed)\n",
    "mapping = {}\n",
    "for pdf in pdf_files:\n",
    "    base, _ = os.path.splitext(pdf)            \n",
    "    if base in txt_basenames:\n",
    "        mapping[base] = base                     # exact match\n",
    "    else:\n",
    "        # find the single best match above a 0.8 similarity threshold\n",
    "        candidates = difflib.get_close_matches(base, txt_basenames.keys(), n=1, cutoff=0.8)\n",
    "        mapping[base] = candidates[0] if candidates else None\n",
    "\n",
    "# (Optional) print out any that still didn’t match\n",
    "unmatched = [b for b,m in mapping.items() if m is None]\n",
    "if unmatched:\n",
    "    print(\" No .txt match for these basenames:\")\n",
    "    for u in unmatched:\n",
    "        print(\"   \", u)\n",
    "\n",
    "# 4. Load each contract’s text via the mapping\n",
    "docs_texts = []\n",
    "for pdf in pdf_files:\n",
    "    base, _ = os.path.splitext(pdf)\n",
    "    txt_base = mapping.get(base)\n",
    "    if txt_base:\n",
    "        path = os.path.join(TXT_FOLDER, txt_base + '.txt')\n",
    "        try:\n",
    "            with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "                docs_texts.append(f.read())\n",
    "        except Exception as e:\n",
    "            print(f\"Failed reading {path}: {e}\")\n",
    "            docs_texts.append(\"\")\n",
    "    else:\n",
    "        # no good match found\n",
    "        docs_texts.append(\"\")\n",
    "        \n",
    "df_checks = pd.DataFrame(docs_texts)\n",
    "print(df_checks.head(20))\n",
    "rows, cols = df_checks.shape\n",
    "print(f\"There are {rows} rows and {cols} columns.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb9c62",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Embed with SBERT\n",
    "model     = SentenceTransformer('Stern5497/sbert-legal-xlm-roberta-base')\n",
    "doc_embs  = model.encode(docs_texts, show_progress_bar=True)\n",
    "\n",
    "# 6. Save to disk\n",
    "output_df = pd.DataFrame({\n",
    "    'Filename': pdf_files,\n",
    "    'embedding': list(doc_embs)\n",
    "})\n",
    "output_df.to_pickle(OUTPUT_PKL)\n",
    "print(f\"Encoded {len(doc_embs)} documents and saved to {OUTPUT_PKL}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docquery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
